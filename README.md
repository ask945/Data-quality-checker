________________________________________
Data-Quality-Checker ğŸ›¡ï¸
Data-Quality-Checker is a lightweight framework designed to ensure data integrity by automatically identifying anomalies and outliers in datasets. It helps maintain reliable, consistent, and clean data for analysis or downstream applications.
By catching hidden errors early, it improves the trustworthiness of datasets, reduces the risk of faulty insights, and ensures higher-quality results in analytics and machine learning pipelines.
________________________________________
ğŸš€ Features
Two Modes of Operation
1.	SQL Mode ğŸ—„ï¸
o	Upload one or more files and define table relationships (One-to-One,One-to-Many,Many-to-One,Many-to-Many)
o	Detect issues like:
ï‚§	Numeric anomalies 
ï‚§	Categorical anomalies
ï‚§	Complex pattern anomalies
ï‚§	Insertion, Deletion, and Update anomalies
2.	ML Mode ğŸ¤–
o	Upload a file to detect outliers and anomalies.
o	Detect issues like:
ï‚§	Numeric anomalies 
ï‚§	Categorical anomalies
ï‚§	Complex pattern anomalies

________________________________________
ğŸ•µï¸â€â™‚ï¸ What It Detects
Outliers
1.	Numeric anomalies
o	Extreme or unusual numerical values that deviate from the datasetâ€™s distribution
o	Detected using z-score (distance from mean) and IQR (values outside Q1â€“Q3 range)
2.	Categorical anomalies
o	Rare or unexpected values in categorical columns that occur with very low frequency
3.	Complex pattern anomalies
o	Detected using LightGBM
o	Models patterns in data and assigns anomaly scores to identify unusual or rare observations
________________________________________
Anomalies
1.	Insertion Anomalies â•
o	Duplicate records â€“ Multiple rows have identical values
o	Missing required fields â€“ Columns that should always have values are missing
o	Invalid foreign keys â€“ Foreign key values are incorrect
o	Insertion anomalies = Duplicate records + Missing required fields + Invalid foreign keys

2.	Deletion Anomalies â–
o	Orphaned records â€“ Child records reference non-existent parent records
o	Referential integrity violations â€“ Foreign key constraints are broken
o	Potential accidental deletions â€“ Normally critical columns suddenly missing values
o	Deletion anomalies = Orphaned records + Referential integrity violations + Potential accidental deletions

3.	Update Anomalies ğŸ”„
o	Inconsistent updates â€“ Same key has conflicting values in other columns
o	Partial updates â€“ Only some related columns were updated
o	Data type violations â€“ Column values do not match expected type
o	Update anomalies = Inconsistent updates + Partial updates + Data type violations
________________________________________
ğŸ“Š Data Quality Score
The Data Quality Score measures how clean and reliable your dataset is. It is calculated based on the proportion of anomalies detected:
1.	Anomaly Percentage â€“ This is the fraction of rows in your dataset that contain anomalies:
            Anomaly Percentage = Total Anomalies Ã· Total Rows
2.	Quality Score â€“ The quality score is calculated by subtracting the anomaly percentage from 100, ensuring that higher anomaly counts reduce the score. The minimum score is 0.
            Quality Score = 100 âˆ’ Anomaly Percentage
________________________________________
ğŸ” Confidence & Severity
â€¢	Confidence
o	Complex pattern anomalies: Probability output from LightGBM, where scores closer to 1 indicate higher anomaly likelihood
o	Other anomalies: confidence = 1 (binary anomaly detection: yes/no)
â€¢	Method Weight âš–ï¸
o	Assigns importance to each type of anomaly based on its potential impact
â€¢	Severity Score ğŸ’¥
o	Combines detection confidence and method weight:
o	severity_score = confidence Ã— method_weight
________________________________________
âœ… Data-Quality-Checker ensures your datasets are clean, reliable, and ready for analysis or ML pipelines.
________________________________________

